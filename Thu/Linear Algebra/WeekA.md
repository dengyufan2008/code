# WeekA Homework (Textbook)

By Deng Yufan.

## P321 T1

a. There exists a linear operator $T$ with no $T$-invariant subspace.

b. If $T$ is a linear operator on a finite-dimensional vector space $V$ and $W$ is a $T$-invariant subspace of $V$, then the characteristic polynomial of $T_W$ divides the characteristic polynomial of $T$.

c. Let $T$ be a linear operator on a finite-dimensional vector space $V$, and let $v$ and $w$ be in $V$. If $W$ is the $T$-cyclic subspace generated by $v$, $W'$ is the $T$-cyclic subspace generated by $w$, and $W = W'$, then $v = w$.

d. If $T$ is a linear operator on a finite-dimensional vector space $V$, then for any $v \in V$ the $T$-cyclic subspace generated by $v$ is the same as the $T$-cyclic subspace generated by $T(v)$.

e. Let $T$ be a linear operator on an $n$-dimensional vector space. Then there exists a polynomial $g(t)$ of degree $n$ such that $g(T) = T_0$.

f. Any polynomial of degree $n$ with leading coefficient $(-1)^n$ is the characteristic polynomial of some linear operator.

g. If $T$ is a linear operator on a finite-dimensional vector space $V$, and if $V$ is the direct sum of $k$ $T$-invariant subspaces, then there is an ordered basis $\beta$ for $V$ such that $[T]_\beta$ is a direct sum of $k$ matrices.

a. False. b. True. c. False. d. False. e. True. f. True. g. True.

## P322 T2

For each of the following linear operators $T$ on the vector space $V$, determine whether the given subspace $W$ is a $T$-invariant subspace of $V$.

b. $V=P(R)$, $T(f(x))=xf(x)$, and $W=P_2(R)$.

e. $V=M_{2 \times 2}(R)$, $T(A) = \left[\begin{matrix}0 & 1 \\ 1 & 0\end{matrix}\right]A$, and $W = \{A \in V \mid A^t = A\}$.

---

b. We have $f(x)=x^2 \in W$, but $T(f(x))=x^3 \notin W$. So $W$ is not $T$-invariant.

e. We have $\left[\begin{matrix}1 & 2 \\ 2 & 3\end{matrix}\right] \in W$, but $T(\left[\begin{matrix}1 & 2 \\ 2 & 3\end{matrix}\right]) = \left[\begin{matrix}2 & 3 \\ 1 & 2\end{matrix}\right] \notin W$. So $W$ is not $T$-invariant.

## P322 T6

For each linear operator $T$ on the vector space $V$, find an ordered basis for the $T$-cyclic subspace generated by the vector $z$.

b. $V=P_3(R)$, $T(f(x))=f''(x)$, and $z=x^3$.

---

b. We have $T(z)=6x$, $T^2(z)=0$. So $T^k(z) = 0 \space (k \ge 2)$. Then $\text{span}\{z, T(z), \cdots\} = \text{span}\{x, x^3\}$. So a ordered basis is $\beta = \{x, x^3\}$.

## P323 T17

Let $A$ be an $n \times n$ matrix. Prove that $\dim(\text{span}(\{I_n, A, A^2,\cdots\})) \le n$.

---

Obviously $W = \text{span}(\{I_n, A, A^2,\cdots\})$ is the $T$-cyclic subspace of $I_n$, where $T:M_{n \times n} \rightarrow M_{n \times n}$ that $T(B)=AB$. Let $k=\dim(W)$.

If $k > n$, since $\{I_n, A, A^2, \cdots, A^{k-1}\}$ is a basis of $W$, then $\{I_n, A, A^2, \cdots, A^n\}$ is independent.

Let $g(t) = \det(A-tI) = \sum_{i=0}^n a_i t^i$. Since $g(A)=0$, $\sum_{i=0}^n a_i A^i = 0$, and $a_n \ne 0$, contradiction.

## P324 T23

Let $T$ be a linear operator on a finite-dimensional vector space $V$, and let $W$ be a $T$-invariant subspace of $V$. Suppose that $v_1, v_2,\cdots,v_k$ are eigenvectors of $T$ corresponding to distinct eigenvalues. Prove that if $v_1 +v_2 +\cdots+v_k$ is in $W$, then $v_i \in W$ for all $i$.

---

Induction $k$ to prove: if for some $a_i \ne 0$ that $\sum_{i=1}^k a_i v_i \in W$, then $v_i \in W$. This complete the proof.

As basis, when $k=1$ is obviously true. We assume $k-1$ and prove $k$.

We have $\sum_{i=1}^k a_i \lambda_i v_i = \sum_{i=1}^k a_i T(v_i) = T(\sum_{i=1}^k a_i v_i) \in W$. So $\sum_{i=1}^{k-1} a_i (\lambda_i - \lambda_k) v_i = (\sum_{i=1}^k a_i \lambda_i v_i) - \lambda_k(\sum_{i=1}^k a_i v_i) \in W$. Since $a_i \ne 0$, $\lambda_i \ne \lambda_k$ for $i \ne k$, so we can use the induction assumption to claim $v_i \in W$ for $i \ne k$. So $a_kv_k = (\sum_{i=1}^k a_i v_i) - a_1v_1 - a_2v_2 - \cdots - a_{k-1}v_{k-1} \in W$, $v_k \in W$.

## P324 T24

Prove that the restriction of a diagonalizable linear operator $T$ to any nontrivial $T$-invariant subspace is also diagonalizable.

---

Formally speaking, we proof if $T:V \rightarrow V$ is diagonalizable, then for all $T$-invariant nonzero subspace $W$, $T_W$ is diagonalizable.

Let $k$ be the number of eigenvalues of $T$, $m = \dim(W)$, and $\lambda_1, \lambda_2, \cdots, \lambda_k$ be distinct eigenvalues, $\beta = \{\beta_1, \beta_2, \cdots, \beta_m\}$ be a basis of $W$.

Since $V = E_{\lambda_1} \oplus \cdots \oplus E_{\lambda_k}$. For all $1 \le i \le m$, we can uniquely have $\beta_i = v_{i1}+v_{i2}+\cdots+v_{ik}$ that $v_{ij} \in E_{\lambda_j}$. According to P324 T23, $v_{ij} \in W$.

Let $W' = \text{span}\{v_{i1} \mid 1 \le i \le m\} \oplus \text{span}\{v_{i2} \mid 1 \le i \le m\} \oplus \cdots \oplus \text{span}\{v_{ik} \mid 1 \le i \le m\}$. Obviously $\beta_i \in W'$, so $W \subseteq W'$. And we also have $v_{ij} \in W$, so $W' \subseteq W$. Thus $W=W'$.

Let $\beta'_j$ be a basis of $\text{span}\{v_{ij} \mid 1 \le i \le m\}$, which is subspace of $E_{\lambda_j}$, then $\beta' = \bigcup_{j=1}^k \beta'_j$ is a basis of $W$. Obvisouly $\beta'$ consist only eigenvectors, so $W$ is diagonalizable.

## P325 T25

a. Prove if $T$ and $U$ are diagonalizable linear operators on a finite-dimensional vector space $V$ such that $UT = TU$, then $T$ and $U$ are simultaneously diagonalizable.

---

a. Let $k$ be the number of eigenvalue of $T$. For all eigenvalue $\lambda_i$ of $T$, for all $x \in E_{\lambda_i}$, we have $\lambda_i U(x) = U(\lambda_i x) = U(T(x)) = T(U(x))$. So $U(x) \in E_{\lambda_i}$, thus $E_{\lambda_i}$ is $U$-invariant.

According to P324 T24, $U_{E_{\lambda_i}}$ is diagonalizable. Let $\beta_i$ be a basis of $E_{\lambda_i}$ that $[U_{E_{\lambda_i}}]_{\beta_i}$ is diagonal.

Let $\beta = \bigcup_{i=1}^k \beta_i$. We have $\bigoplus_{i=1}^k [U_{E_{\lambda_i}}]_{\beta_i} = [U]_\beta$. So $[U]_\beta$ is diagonal. Since $\beta$ consist only eigenvector of $T$, so $[T]_\beta$ is diagonal.

## P325 T28

Let $T$ be a linear operator on a vector space $V$, and let $W$ be a $T$-invariant subspace of $V$. Define $\overline T: V/W \rightarrow V/W$ by $\overline T(v+W)=T(v)+W$.

Let $f(t)$, $g(t)$, and $h(t)$ be the characteristic polynomials of $T$, $T_W$, and $\overline T$, respectively. Prove that $f(t) = g(t)h(t)$.

---

Let $n=\dim(V)$, $m=\dim(W)$, $\beta' = \{\beta_1, \beta_2, \cdots, \beta_m\}$ be a basis of $W$, and we can have $\beta=\{\beta_1, \beta_2, \cdots, \beta_n\}$ be a basis of $V$.

Obviously $[T]_\beta = \left[\begin{matrix}A & B \\ O & C\end{matrix}\right]$, where $A=[T_W]_{\beta'}$. We prove $\beta'' = \{\beta_{m+1}+W, \cdots, \beta_n+W\}$ is a basis of $V/W$ and $[\overline T]_{\beta''}=C$. This complete the prove since $\det(T-tI)=\det(A-tI)\det(C-tI)=\det(T_W-tI)\det(\overline T-tI)$.

For all $m+1 \le i \le n$, $T(\beta_i) = \sum_{j=1}^m B_{j,i-m}\beta_j + \sum_{j=m+1}^n C_{j-m, i-m}\beta_j$, so $\overline T(\beta_i+W) = \sum_{j=1}^m B_{j,i-m}\beta_j + \sum_{j=m+1}^n C_{j-m, i-m}\beta_j + W = (\sum_{j=1}^m B_{j,i-m}\beta_j + W) + (\sum_{j=m+1}^n C_{j-m, i-m}\beta_j + W)$. Since $\beta_j \in W$ for $j \le m$, then $\sum_{j=1}^m B_{j,i-m}\beta_j + W = 0 + W$. So $\overline T(\beta_i+W) = \sum_{j=m+1}^n C_{j-m, i-m}\beta_j + W = \sum_{j=m+1}^n C_{j-m,i-m} (\beta_j+W)$, thus $[\overline T]_{\beta''}=C$.

## P326 T31

Let $A=\left[\begin{matrix}1 & 1 & -3 \\ 2 & 3 & 4 \\ 1 & 2 & 1\end{matrix}\right]$, let $T=L_A$, and let $W$ be the cyclic subspace of $R^3$ generated by $e_1$.

a. Use Theorem 5.22 to compute the characteristic polynomial of $T_W$.

b. Show that $\{e_2 + W\}$ is a basis for $R^3/W$, and use this fact to compute the characteristic polynomial of $\overline T$.

c. Use the results of (a) and (b) to find the characteristic polynomial of $A$.

---

a. We have $T(e_1)=\left[\begin{matrix}1 \\ 2 \\ 1\end{matrix}\right]$, $T^2(e_1)=\left[\begin{matrix}0 \\ 12 \\ 6\end{matrix}\right] = -6e_1 + 6T(e_1)$. So $\det(T_W-tI)=(-1)^2(6-6t+t^2)=6-6t+t^2$.

b. Since $W=\text{span}\{e_1, T(e_1)\}=\text{span}\{e_1, 2e_2+e_3\}$, $\dim(W)=2$, so $\dim(R^3/W)=\dim(R^3)-\dim(W)=1$. Since $e_2+W \in R^3/W$ and $e_2 \notin W$, so $e_2+W \ne 0+W$, thus $\{e_2+W\}$ is independent. So $\beta=\{e_2+W\}$ is a basis of $R^3/W$.

We have $\overline T(e_2+W)=T(e_2)+W=e_1+3e_2+2e_3+W=-e_2+W$, so $[\overline T]_\beta=[-1]$. Thus $\det(\overline T-tI)=-1-t$.

c. We have $\det(A-tI)=\det(T-tI)=\det(T_W-tI)\det(\overline T-tI)=-6+5t^2-t^3$.

## P336 T1

a. An inner product is a scalar-valued function on the set of ordered pairs of vectors.

b. An inner product space must be over the field of real or complex numbers.

c. An inner product is linear in both components.

d. There is exactly one inner product on the vector space $R^n$.

e. The triangle inequality only holds in finite-dimensional inner product spaces.

f. Only square matrices have a conjugate-transpose.

g. If $x$, $y$, and $z$ are vectors in an inner product space such that $\langle x, y \rangle = \langle x, z \rangle$, then $y = z$.

h. If $\langle x, y \rangle = 0$ for all $x$ in an inner product space, then $y = 0$.

a. True. b. False. c. False. d. False. e. False. f. False. g. False. h. True.

## P336 T2

Let $x = (2, 1 + i, i)$ and $y = (2 − i, 2, 1+2i)$ be vectors in $C^3$. Compute $\langle x, y \rangle$, $||x||$, $||y||$, and $||x+y||$. Then verify both the Cauchy–Schwarz inequality and the triangle inequality.

---

$\langle x, y \rangle = (4+2i)+(2+2i)+(2+i)=8+5i$.

$||x||=\sqrt{4+2+1}=\sqrt 7$.

$||y||=\sqrt{5+4+5}=\sqrt {14}$.

$||x+y||=\sqrt{17+10+10}=\sqrt {37}$.

$|\langle x, y \rangle|=\sqrt{89} \le \sqrt{98} = ||x|| \cdot ||y||$.

$||x+y|| = \sqrt{37} \le \sqrt{7} + \sqrt{14} = ||x|| + ||y||$.

## P336 T4

a. Complete the proof in Example 5 that $\langle \cdot, \cdot \rangle$ is an inner product (the Frobenius inner product) on $M_{n×n}(F)$.

b. Use the Frobenius inner product to compute $||A||$, $||B||$, and $\langle A, B \rangle$ for $A=\left[\begin{matrix}1 & 2+i \\ 3 & i\end{matrix}\right]$ and $B=\left[\begin{matrix}1+i & 0 \\ i & -i\end{matrix}\right]$.

---

a. We prove $\langle cA, B \rangle = c\langle A, B \rangle$, $\overline{\langle A, B \rangle}=\langle B, A \rangle$.

We have $\langle cA, B \rangle = \text{tr}(B^*(cA)) = c\text{tr}(B^*A) = c\langle A, B \rangle$.

We have $\overline{\langle A, B \rangle} = \overline{\text{tr}(B^*A)} = \text{tr}(\overline{B^*A}) = \text{tr}(B^t \overline{A}) = \text{tr}(A^*B) = \langle B, A \rangle$.

b. $||A||=1+5+9+1=16$, $||B||=2+0+1+1=4$. $\langle A, B \rangle = (1-i)+(0)+(-3i)+(-1)=-4i$.

## P336 T5

In $C^2$, show that $\langle x, y \rangle = xAy^*$ is an inner product, where $A=\left[\begin{matrix}1 & i \\ -i & 2\end{matrix}\right]$. Compute $\langle x, y \rangle$ for $x=(1-i,2+3i)$ and $y=(2+i,3-2i)$.

---

We have $\langle x+z, y \rangle = (x+z)Ay^*=xAy^*+zAy^*=\langle x, y \rangle + \langle z, y \rangle$.

$\langle cx, y \rangle = (cx)Ay^* = cxAy^* = c \langle x, y \rangle$.

$\overline{\langle x, y \rangle} = \overline{xAy^*} = \overline{x} \overline{A} y^t = y A^* x^*$. Since $A^*=A$, so $\overline{\langle x, y \rangle} = yAx^* = \langle y, x \rangle$.

$\langle x, x \rangle = xAx^* = |x_1|^2-x_2\overline{x_1}i+x_1\overline{x_2}i+2|x_2|^2=|x_1|^2+2|x_2|^2-2\text{Image}(x_1 \overline{x_2}) \ge |x_1|^2+2|x_2|^2-2|x_1 \overline{x_2}| = |x_1|^2+2|x_2|^2-2|x_1||x_2| \ge |x_1|^2+|x_2|^2-2|x_1||x_2| = (|x_1|-|x_2|)^2 \ge 0$. $\langle x, x \rangle = 0$ iff $|x_1|=|x_2|=0$, which is $x=0$.

We have $\langle x, y \rangle = 6+21i$.

## P337 T15

a. Prove that if $V$ is an inner product space, then $|\langle x, y \rangle| = ||x|| \cdot ||y||$ if and only if one of the vectors $x$ or $y$ is a multiple of the other.

b. Derive a similar result for the equality $||x+y||=||x||+||y||$, and generalize it to the case of $n$ vectors.

---

a. If: When $x=\lambda y$, $|\langle x, y \rangle| = |\langle \lambda y, y \rangle| = \lambda |\langle x, x \rangle| = \lambda ||x|| \cdot ||x|| = ||x|| \cdot ||y||$. When $y=\lambda x$ it is similar.

Only if: We have $\langle x, y \rangle \langle y, x \rangle = \langle x, x \rangle \langle y, y \rangle$, which is $\langle y, y \rangle = 0$ or $\langle x, x \rangle = \frac{\langle x, y \rangle}{\langle y, y \rangle} \langle y, x \rangle$. If $\langle y, y \rangle = 0$, then $y=0$, the statement obviously true. Otherwise let $\lambda = \frac{\langle x, y \rangle}{\langle y, y \rangle}$, we have $\langle x, x \rangle - \lambda \langle y, x \rangle = 0$.

Moreover, we have $\lambda \overline{\lambda} \langle y, y \rangle - \overline{\lambda} \langle x, y \rangle = 0$, so $\langle x, x \rangle - \lambda \langle y, x \rangle - \overline{\lambda} \langle x, y \rangle + \lambda \overline{\lambda} \langle y, y \rangle = 0$, that is $\langle x-\lambda y, x-\lambda y \rangle = 0$. So $x-\lambda y = 0$, $x=\lambda y$, the statement is true.

b. $||x+y||=||x||+||y||$ iff one of the vectors $x$ or $y$ is a multiple of the other. $||x_1+x_2+\cdots+x_n||=||x_1||+||x_2||+\cdots+||x_n||$ iff $x_i = \lambda_i x_0$ for some scalar $\lambda_i$ and vector $x_0$. Proof is trival.

## P339 T23

Let $V = F^n$, and let $A \in M_{n \times n}(F)$.

a. Prove that $\langle x, Ay \rangle = \langle A^*x, y \rangle$ for all $x, y \in V$.

b. Suppose that for some $B \in M_{n \times n}(F)$, we have $\langle x, Ay \rangle = \langle Bx, y \rangle$ for all $x, y \in V$. Prove that $B=A^*$.

c. Let $\alpha$ be the standard ordered basis for $V$. For any orthonormal basis $\beta$ for $V$, let $Q$ be the $n \times n$ matrix whose columns are the vectors in $\beta$. Prove that $Q^* = Q^{-1}$.

d. Define linear operators $T$ and $U$ on $V$ by $T(x) = Ax$ and $U(x) = A^*x$. Show that $[U]_β = [T]^*_β$ for any orthonormal basis $\beta$ for $V$.

---

a. We have $\langle x, Ay \rangle = \sum_{i=1}^n x_i \overline{(Ay)_i} = \sum_{i=1}^n x_i \sum_{j=1}^n \overline{A_{ij}}\overline{y_j} = \sum_{j=1}^n \overline{y_j} \sum_{i=1}^n A^*_{ji} x_i = \sum_{j=1}^n \overline{y_j} (A^*x)_j = \langle A^* x, y \rangle$.

b. We have $\langle Bx, y \rangle = \langle x, Ay \rangle = \langle A^* x, y \rangle$, so $\langle (B-A^*)x, y \rangle = 0$. For all $1 \le i \le n$, we have $\langle (B-A^*) e_i, (B-A^*) e_i \rangle = 0$, so $(B-A^*)e_i = 0$. Thus $B-A^*=0$, $B=A^*$.

c. Obviously $Q$ changes $\beta$-coor into $\alpha$-coor, so $Q^{-1}$ exists. We prove $\langle x, Qy \rangle = \langle Q^{-1}x, y \rangle$ for all $x, y \in V$. Let $z = Q^{-1} y$, we prove $\langle Qz, Qy \rangle = \langle z, y \rangle$.

We have $\langle Qz, Qy \rangle = \sum_{i=1}^n \sum_{j=1}^n z_i \overline{y_j}\langle \beta_i, \beta_j \rangle = \sum_{i=1}^n \sum_{j=1}^n z_i \overline{y_j} [i=j] = \sum_{i=1}^n z_i \overline{y_i} = \langle x, y \rangle$.

d. Let $Q$ changes $\beta$-coor into $\alpha$-coor. We prove $Q^{-1}AQ = (Q^{-1}A^*Q)^*$. Since $Q^* = Q^{-1}$, we have $(Q^{-1}A^*Q)^* = (Q^*A^*Q)^* = \overline{Q^t \overline{A} \space \overline{Q}} = Q^*AQ = Q^{-1}AQ$.
